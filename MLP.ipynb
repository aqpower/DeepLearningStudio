{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./MLP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(\n",
    "        self, num_input_node, num_hidden_node, num_output_node, learning_rate=0.01\n",
    "    ):\n",
    "\n",
    "        self.num_input_node = num_input_node\n",
    "        self.num_hidden_node = num_hidden_node\n",
    "        self.num_output_node = num_output_node\n",
    "\n",
    "        # 权重被初始化为正态分布的随机数，其均值为0，标准差为隐藏节点数或输出节点数的平方根的倒数。\n",
    "        self.wih = np.random.normal(\n",
    "            0.0,\n",
    "            pow(self.num_hidden_node, -0.5),\n",
    "            (self.num_hidden_node, self.num_input_node),\n",
    "        )\n",
    "        self.who = np.random.normal(\n",
    "            0,\n",
    "            pow(self.num_output_node, -0.5),\n",
    "            (self.num_output_node, self.num_hidden_node),\n",
    "        )\n",
    "\n",
    "        self.lr = learning_rate \n",
    "        # expit 是sigmoid函数\n",
    "        self.activation_function = lambda x: expit(x)\n",
    "\n",
    "    def predict(self, input_item):\n",
    "        out_hidden = self.activation_function(np.dot(self.wih, input_item))\n",
    "        out_output = self.activation_function(np.dot(self.who, out_hidden))\n",
    "\n",
    "        ground_truth = np.argmax(out_output)\n",
    "        return ground_truth\n",
    "\n",
    "    # * 一次训练一个样本\n",
    "    def train(self, input, label, iter_nums=20):\n",
    "        # correct_cnt = 0\n",
    "        for i in range(iter_nums):\n",
    "\n",
    "            # step 1: Forward Propagation\n",
    "            out_hidden = self.activation_function(np.dot(self.wih, input))\n",
    "            out_output = self.activation_function(np.dot(self.who, out_hidden))\n",
    "\n",
    "            # step 2: loss backpropagation\n",
    "            error_output = label - out_output\n",
    "            error_hidden = np.dot(self.who.T, error_output)\n",
    "\n",
    "            # step 3: update the weights\n",
    "            self.who += self.lr * np.dot(\n",
    "                (error_output * out_output * (1.0 - out_output)),\n",
    "                np.transpose(out_hidden),\n",
    "            )\n",
    "            self.wih += self.lr * np.dot(\n",
    "                (error_hidden * out_hidden * (1.0 - out_hidden)), np.transpose(input)\n",
    "            )\n",
    "\n",
    "            # calculate the correct radix\n",
    "            # ground_truth = np.argmax(out_output)\n",
    "            # label_val = np.where(label == 1)[0][0]\n",
    "            # if ground_truth == label_val:\n",
    "            # correct_cnt += 1\n",
    "\n",
    "            # if i % 49 == 0:\n",
    "            #     print(\n",
    "            #         f\"iteration {i} label:{label_val} ground truth:{ ground_truth}, Correct: {label_val == ground_truth}\"\n",
    "            #     )\n",
    "        # print(f\"correct radix is {correct_cnt / iter_nums}\")\n",
    "\n",
    "    def evaluate_model(self, test_data):\n",
    "        correct_predictions = 0\n",
    "        total_loss = 0\n",
    "        num_samples = len(test_data)\n",
    "\n",
    "        for _, sample in enumerate(test_data):\n",
    "            input_data, true_label = sample\n",
    "            input_data = np.array(input_data) / 255.0\n",
    "            input_data = input_data.reshape(28 * 28, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            hidden_output = self.activation_function(np.dot(self.wih, input_data))\n",
    "            final_output = self.activation_function(np.dot(self.who, hidden_output))\n",
    "\n",
    "            # Predict the label\n",
    "            predicted_label = self.predict(input_data)\n",
    "\n",
    "            # Check if the prediction is correct\n",
    "            if predicted_label == true_label:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            true_label_one_hot = np.zeros(final_output.shape)\n",
    "            true_label_one_hot[true_label] = 1\n",
    "\n",
    "            # Compute the loss for this sample\n",
    "            sample_loss = -np.sum(true_label_one_hot * np.log(final_output))\n",
    "            total_loss += sample_loss\n",
    "\n",
    "        # Calculate average loss and accuracy\n",
    "        average_loss = total_loss / num_samples\n",
    "        accuracy = correct_predictions / num_samples\n",
    "\n",
    "        # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        # print(f\"Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "        return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "train_data = MNIST(root=\"data\", train=True, download=True)\n",
    "test_data = MNIST(root=\"data\", train=False, download=True)\n",
    "train_list = list(train_data)\n",
    "test_list = list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(lr):\n",
    "    num_input_node = 28 * 28\n",
    "    num_hidden_node = 80\n",
    "    num_output_node = 10\n",
    "\n",
    "    mlp_model = MLP(num_input_node, num_hidden_node, num_output_node, lr)\n",
    "\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    iteration_list = []\n",
    "\n",
    "    #* train only one train sample during a train epoch\n",
    "    for i, item in enumerate(train_list):\n",
    "        input = np.array(item[0])\n",
    "        # Normalize the input because the input is the pixel value of the image, and the activation function is sigmoid\n",
    "        input = (input / 255.0).reshape(28 * 28, 1)\n",
    "        label = np.zeros((10, 1))\n",
    "        label[item[1]] = 1\n",
    "\n",
    "        mlp_model.train(input, label)\n",
    "\n",
    "        # evaluate the model every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy, train_loss = mlp_model.evaluate_model(train_list)\n",
    "            test_accuracy, test_loss = mlp_model.evaluate_model(test_list)\n",
    "\n",
    "            train_accuracy_list.append(train_accuracy)\n",
    "            test_accuracy_list.append(test_accuracy)\n",
    "            train_loss_list.append(train_loss)\n",
    "            test_loss_list.append(test_loss)\n",
    "            iteration_list.append(i)\n",
    "\n",
    "            print(\n",
    "                f\"•----- lr {lr:<5} Iteration {i:<5} ----- Train Accuracy: {train_accuracy:<6.2f} ----- Test Accuracy: {test_accuracy:<6.2f} ----- Train Loss: {train_loss:<6.2f} ----- Test Loss: {test_loss:<6.2f} -----•\"\n",
    "            )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        iteration_list,\n",
    "        train_accuracy_list,\n",
    "        label=\"Training Accuracy\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.plot(\n",
    "        iteration_list,\n",
    "        test_accuracy_list,\n",
    "        label=\"Testing Accuracy\",\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Iterations\", fontsize=14)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "    plt.title(f\"Training and Testing Accuracy (Learning Rate: {lr})\", fontsize=16)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # save the plot as svg and emf \n",
    "    svg_path_accuracy = f\"./images/mnist_train_lr{lr}_accuracy_plot.svg\"\n",
    "    emf_path_accuracy = f\"./images/mnist_train_lr{lr}_accuracy_plot.emf\"\n",
    "    plt.savefig(svg_path_accuracy)\n",
    "    subprocess.run(\n",
    "        f\"inkscape --export-filename={emf_path_accuracy} {svg_path_accuracy}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # visualize the loss plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        iteration_list,\n",
    "        train_loss_list,\n",
    "        label=\"Training Loss\",\n",
    "        color=\"red\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.plot(\n",
    "        iteration_list,\n",
    "        test_loss_list,\n",
    "        label=\"Testing Loss\",\n",
    "        color=\"orange\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.ylim(0, max(max(train_loss_list), max(test_loss_list)) * 1.1)\n",
    "    plt.xlabel(\"Iterations\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.title(f\"Training and Testing Loss (Learning Rate: {lr})\", fontsize=16)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    svg_path_loss = f\"./images/mnist_train_lr{lr}_loss_plot.svg\"\n",
    "    emf_path_loss = f\"./images/mnist_train_lr{lr}_loss_plot.emf\"\n",
    "    plt.savefig(svg_path_loss)\n",
    "    subprocess.run(\n",
    "        f\"inkscape --export-filename={emf_path_loss} {svg_path_loss}\", shell=True\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "•----- lr 0.001 Iteration 0     ----- Train Accuracy: 0.10   ----- Test Accuracy: 0.09   ----- Train Loss: 1.02   ----- Test Loss: 1.02   -----•\n",
      "•----- lr 0.001 Iteration 100   ----- Train Accuracy: 0.38   ----- Test Accuracy: 0.38   ----- Train Loss: 1.79   ----- Test Loss: 1.81   -----•\n",
      "•----- lr 0.001 Iteration 200   ----- Train Accuracy: 0.50   ----- Test Accuracy: 0.50   ----- Train Loss: 1.56   ----- Test Loss: 1.56   -----•\n",
      "•----- lr 0.001 Iteration 300   ----- Train Accuracy: 0.58   ----- Test Accuracy: 0.57   ----- Train Loss: 1.45   ----- Test Loss: 1.46   -----•\n",
      "•----- lr 0.001 Iteration 400   ----- Train Accuracy: 0.62   ----- Test Accuracy: 0.63   ----- Train Loss: 1.28   ----- Test Loss: 1.28   -----•\n",
      "•----- lr 0.001 Iteration 500   ----- Train Accuracy: 0.68   ----- Test Accuracy: 0.69   ----- Train Loss: 1.23   ----- Test Loss: 1.24   -----•\n",
      "•----- lr 0.001 Iteration 600   ----- Train Accuracy: 0.70   ----- Test Accuracy: 0.70   ----- Train Loss: 1.14   ----- Test Loss: 1.14   -----•\n",
      "•----- lr 0.001 Iteration 700   ----- Train Accuracy: 0.70   ----- Test Accuracy: 0.69   ----- Train Loss: 1.10   ----- Test Loss: 1.10   -----•\n",
      "•----- lr 0.001 Iteration 800   ----- Train Accuracy: 0.74   ----- Test Accuracy: 0.74   ----- Train Loss: 1.04   ----- Test Loss: 1.04   -----•\n",
      "•----- lr 0.001 Iteration 900   ----- Train Accuracy: 0.75   ----- Test Accuracy: 0.75   ----- Train Loss: 0.99   ----- Test Loss: 0.99   -----•\n",
      "•----- lr 0.001 Iteration 1000  ----- Train Accuracy: 0.71   ----- Test Accuracy: 0.71   ----- Train Loss: 0.97   ----- Test Loss: 0.98   -----•\n",
      "•----- lr 0.001 Iteration 1100  ----- Train Accuracy: 0.75   ----- Test Accuracy: 0.76   ----- Train Loss: 1.01   ----- Test Loss: 1.02   -----•\n",
      "•----- lr 0.001 Iteration 1200  ----- Train Accuracy: 0.74   ----- Test Accuracy: 0.74   ----- Train Loss: 0.96   ----- Test Loss: 0.96   -----•\n",
      "•----- lr 0.001 Iteration 1300  ----- Train Accuracy: 0.77   ----- Test Accuracy: 0.77   ----- Train Loss: 0.80   ----- Test Loss: 0.79   -----•\n",
      "•----- lr 0.001 Iteration 1400  ----- Train Accuracy: 0.77   ----- Test Accuracy: 0.77   ----- Train Loss: 0.78   ----- Test Loss: 0.78   -----•\n",
      "•----- lr 0.001 Iteration 1500  ----- Train Accuracy: 0.80   ----- Test Accuracy: 0.79   ----- Train Loss: 0.82   ----- Test Loss: 0.82   -----•\n",
      "•----- lr 0.001 Iteration 1600  ----- Train Accuracy: 0.79   ----- Test Accuracy: 0.80   ----- Train Loss: 0.83   ----- Test Loss: 0.83   -----•\n",
      "•----- lr 0.001 Iteration 1700  ----- Train Accuracy: 0.78   ----- Test Accuracy: 0.79   ----- Train Loss: 0.88   ----- Test Loss: 0.88   -----•\n",
      "•----- lr 0.001 Iteration 1800  ----- Train Accuracy: 0.79   ----- Test Accuracy: 0.79   ----- Train Loss: 0.85   ----- Test Loss: 0.84   -----•\n",
      "•----- lr 0.001 Iteration 1900  ----- Train Accuracy: 0.81   ----- Test Accuracy: 0.81   ----- Train Loss: 0.81   ----- Test Loss: 0.80   -----•\n",
      "•----- lr 0.001 Iteration 2000  ----- Train Accuracy: 0.81   ----- Test Accuracy: 0.81   ----- Train Loss: 0.76   ----- Test Loss: 0.76   -----•\n",
      "•----- lr 0.001 Iteration 2100  ----- Train Accuracy: 0.81   ----- Test Accuracy: 0.82   ----- Train Loss: 0.76   ----- Test Loss: 0.75   -----•\n",
      "•----- lr 0.001 Iteration 2200  ----- Train Accuracy: 0.81   ----- Test Accuracy: 0.82   ----- Train Loss: 0.79   ----- Test Loss: 0.78   -----•\n",
      "•----- lr 0.001 Iteration 2300  ----- Train Accuracy: 0.82   ----- Test Accuracy: 0.83   ----- Train Loss: 0.75   ----- Test Loss: 0.74   -----•\n",
      "•----- lr 0.001 Iteration 2400  ----- Train Accuracy: 0.83   ----- Test Accuracy: 0.83   ----- Train Loss: 0.75   ----- Test Loss: 0.74   -----•\n",
      "•----- lr 0.001 Iteration 2500  ----- Train Accuracy: 0.80   ----- Test Accuracy: 0.81   ----- Train Loss: 0.76   ----- Test Loss: 0.75   -----•\n",
      "•----- lr 0.001 Iteration 2600  ----- Train Accuracy: 0.83   ----- Test Accuracy: 0.83   ----- Train Loss: 0.71   ----- Test Loss: 0.71   -----•\n",
      "•----- lr 0.001 Iteration 2700  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.84   ----- Train Loss: 0.70   ----- Test Loss: 0.69   -----•\n",
      "•----- lr 0.001 Iteration 2800  ----- Train Accuracy: 0.83   ----- Test Accuracy: 0.84   ----- Train Loss: 0.71   ----- Test Loss: 0.70   -----•\n",
      "•----- lr 0.001 Iteration 2900  ----- Train Accuracy: 0.82   ----- Test Accuracy: 0.83   ----- Train Loss: 0.73   ----- Test Loss: 0.72   -----•\n",
      "•----- lr 0.001 Iteration 3000  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.85   ----- Train Loss: 0.71   ----- Test Loss: 0.70   -----•\n",
      "•----- lr 0.001 Iteration 3100  ----- Train Accuracy: 0.82   ----- Test Accuracy: 0.83   ----- Train Loss: 0.71   ----- Test Loss: 0.70   -----•\n",
      "•----- lr 0.001 Iteration 3200  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.67   ----- Test Loss: 0.66   -----•\n",
      "•----- lr 0.001 Iteration 3300  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.85   ----- Train Loss: 0.69   ----- Test Loss: 0.68   -----•\n",
      "•----- lr 0.001 Iteration 3400  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.85   ----- Train Loss: 0.70   ----- Test Loss: 0.69   -----•\n",
      "•----- lr 0.001 Iteration 3500  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.85   ----- Train Loss: 0.68   ----- Test Loss: 0.67   -----•\n",
      "•----- lr 0.001 Iteration 3600  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.84   ----- Train Loss: 0.68   ----- Test Loss: 0.67   -----•\n",
      "•----- lr 0.001 Iteration 3700  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.67   ----- Test Loss: 0.66   -----•\n",
      "•----- lr 0.001 Iteration 3800  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.85   ----- Train Loss: 0.69   ----- Test Loss: 0.68   -----•\n",
      "•----- lr 0.001 Iteration 3900  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.86   ----- Train Loss: 0.66   ----- Test Loss: 0.65   -----•\n",
      "•----- lr 0.001 Iteration 4000  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.60   ----- Test Loss: 0.59   -----•\n",
      "•----- lr 0.001 Iteration 4100  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.85   ----- Train Loss: 0.61   ----- Test Loss: 0.60   -----•\n",
      "•----- lr 0.001 Iteration 4200  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.67   ----- Test Loss: 0.66   -----•\n",
      "•----- lr 0.001 Iteration 4300  ----- Train Accuracy: 0.84   ----- Test Accuracy: 0.84   ----- Train Loss: 0.66   ----- Test Loss: 0.66   -----•\n",
      "•----- lr 0.001 Iteration 4400  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.62   ----- Test Loss: 0.61   -----•\n",
      "•----- lr 0.001 Iteration 4500  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.60   ----- Test Loss: 0.59   -----•\n",
      "•----- lr 0.001 Iteration 4600  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.60   ----- Test Loss: 0.59   -----•\n",
      "•----- lr 0.001 Iteration 4700  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.59   ----- Test Loss: 0.58   -----•\n",
      "•----- lr 0.001 Iteration 4800  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.62   ----- Test Loss: 0.61   -----•\n",
      "•----- lr 0.001 Iteration 4900  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.86   ----- Train Loss: 0.58   ----- Test Loss: 0.57   -----•\n",
      "•----- lr 0.001 Iteration 5000  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.60   ----- Test Loss: 0.59   -----•\n",
      "•----- lr 0.001 Iteration 5100  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.57   ----- Test Loss: 0.56   -----•\n",
      "•----- lr 0.001 Iteration 5200  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.59   ----- Test Loss: 0.58   -----•\n",
      "•----- lr 0.001 Iteration 5300  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.56   ----- Test Loss: 0.55   -----•\n",
      "•----- lr 0.001 Iteration 5400  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.56   ----- Test Loss: 0.55   -----•\n",
      "•----- lr 0.001 Iteration 5500  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.57   ----- Test Loss: 0.56   -----•\n",
      "•----- lr 0.001 Iteration 5600  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.59   ----- Test Loss: 0.58   -----•\n",
      "•----- lr 0.001 Iteration 5700  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.57   ----- Test Loss: 0.56   -----•\n",
      "•----- lr 0.001 Iteration 5800  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.55   ----- Test Loss: 0.54   -----•\n",
      "•----- lr 0.001 Iteration 5900  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.56   ----- Test Loss: 0.55   -----•\n",
      "•----- lr 0.001 Iteration 6000  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 6100  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.87   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 6200  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 6300  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 6400  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.52   ----- Test Loss: 0.51   -----•\n",
      "•----- lr 0.001 Iteration 6500  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.55   ----- Test Loss: 0.54   -----•\n",
      "•----- lr 0.001 Iteration 6600  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.55   ----- Test Loss: 0.54   -----•\n",
      "•----- lr 0.001 Iteration 6700  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.56   ----- Test Loss: 0.55   -----•\n",
      "•----- lr 0.001 Iteration 6800  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.55   ----- Test Loss: 0.54   -----•\n",
      "•----- lr 0.001 Iteration 6900  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7000  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7100  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7200  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7300  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7400  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 7500  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.55   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 7600  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.87   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 7700  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.51   ----- Test Loss: 0.50   -----•\n",
      "•----- lr 0.001 Iteration 7800  ----- Train Accuracy: 0.86   ----- Test Accuracy: 0.87   ----- Train Loss: 0.49   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 7900  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.52   ----- Test Loss: 0.51   -----•\n",
      "•----- lr 0.001 Iteration 8000  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 8100  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.53   ----- Test Loss: 0.52   -----•\n",
      "•----- lr 0.001 Iteration 8200  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 8300  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.51   ----- Test Loss: 0.50   -----•\n",
      "•----- lr 0.001 Iteration 8400  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.49   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 8500  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.47   ----- Test Loss: 0.46   -----•\n",
      "•----- lr 0.001 Iteration 8600  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.48   ----- Test Loss: 0.47   -----•\n",
      "•----- lr 0.001 Iteration 8700  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.49   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 8800  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.50   ----- Test Loss: 0.49   -----•\n",
      "•----- lr 0.001 Iteration 8900  ----- Train Accuracy: 0.85   ----- Test Accuracy: 0.86   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 9000  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.55   ----- Test Loss: 0.54   -----•\n",
      "•----- lr 0.001 Iteration 9100  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.51   ----- Test Loss: 0.50   -----•\n",
      "•----- lr 0.001 Iteration 9200  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.50   ----- Test Loss: 0.49   -----•\n",
      "•----- lr 0.001 Iteration 9300  ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.54   ----- Test Loss: 0.53   -----•\n",
      "•----- lr 0.001 Iteration 9400  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.51   ----- Test Loss: 0.50   -----•\n",
      "•----- lr 0.001 Iteration 9500  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.52   ----- Test Loss: 0.51   -----•\n",
      "•----- lr 0.001 Iteration 9600  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.50   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 9700  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.50   ----- Test Loss: 0.49   -----•\n",
      "•----- lr 0.001 Iteration 9800  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.50   ----- Test Loss: 0.49   -----•\n",
      "•----- lr 0.001 Iteration 9900  ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.50   ----- Test Loss: 0.49   -----•\n",
      "•----- lr 0.001 Iteration 10000 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.88   ----- Train Loss: 0.52   ----- Test Loss: 0.50   -----•\n",
      "•----- lr 0.001 Iteration 10100 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.49   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 10200 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.49   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 10300 ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 10400 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 10500 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 10600 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.47   ----- Test Loss: 0.46   -----•\n",
      "•----- lr 0.001 Iteration 10700 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.50   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 10800 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.47   ----- Test Loss: 0.46   -----•\n",
      "•----- lr 0.001 Iteration 10900 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.47   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 11000 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 11100 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.47   ----- Test Loss: 0.46   -----•\n",
      "•----- lr 0.001 Iteration 11200 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 11300 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.47   ----- Test Loss: 0.46   -----•\n",
      "•----- lr 0.001 Iteration 11400 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 11500 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 11600 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.48   ----- Test Loss: 0.47   -----•\n",
      "•----- lr 0.001 Iteration 11700 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.48   ----- Test Loss: 0.47   -----•\n",
      "•----- lr 0.001 Iteration 11800 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.48   ----- Test Loss: 0.48   -----•\n",
      "•----- lr 0.001 Iteration 11900 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12000 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.44   ----- Test Loss: 0.43   -----•\n",
      "•----- lr 0.001 Iteration 12100 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12200 ----- Train Accuracy: 0.87   ----- Test Accuracy: 0.88   ----- Train Loss: 0.48   ----- Test Loss: 0.47   -----•\n",
      "•----- lr 0.001 Iteration 12300 ----- Train Accuracy: 0.88   ----- Test Accuracy: 0.89   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 12400 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.89   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12500 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12600 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12700 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 12800 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.45   -----•\n",
      "•----- lr 0.001 Iteration 12900 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 13000 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.44   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 13100 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 13200 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 13300 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 13400 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 13500 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 13600 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 13700 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 13800 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 13900 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.45   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 14000 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 14100 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 14200 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.46   ----- Test Loss: 0.44   -----•\n",
      "•----- lr 0.001 Iteration 14300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 14400 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.44   ----- Test Loss: 0.43   -----•\n",
      "•----- lr 0.001 Iteration 14500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 14600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.43   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 14700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 14800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 14900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.43   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 15000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.43   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 15100 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.44   ----- Test Loss: 0.42   -----•\n",
      "•----- lr 0.001 Iteration 15200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.45   ----- Test Loss: 0.43   -----•\n",
      "•----- lr 0.001 Iteration 15300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.43   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 15400 ----- Train Accuracy: 0.89   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 15500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.42   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 15600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 15700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 15800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 15900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 16100 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 16300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16400 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 16700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 16800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 16900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 17000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 17100 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 17200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 17300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 17400 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 17500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 17600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 17700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 17800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 17900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 18000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 18100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 18200 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.40   -----•\n",
      "•----- lr 0.001 Iteration 18300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.42   ----- Test Loss: 0.41   -----•\n",
      "•----- lr 0.001 Iteration 18400 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 18500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 18600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 18700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 18800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 18900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 19000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 19100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 19200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 19300 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 19400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 19500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 19600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 19700 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 19800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 19900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 20000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 20100 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 20200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 20300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 20400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 20500 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.90   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 20600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 20700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 20800 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 20900 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 21000 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.41   ----- Test Loss: 0.39   -----•\n",
      "•----- lr 0.001 Iteration 21100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.40   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 21200 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n",
      "•----- lr 0.001 Iteration 21300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 21400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 21500 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 21600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 21700 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 21800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 21900 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 22000 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 22100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 22200 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 22300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 22400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 22500 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 22600 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 22700 ----- Train Accuracy: 0.90   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.37   -----•\n",
      "•----- lr 0.001 Iteration 22800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 22900 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 23000 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 23100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.36   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 23200 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 23300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 23400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 23500 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 23600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 23700 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 23800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 23900 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 24000 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.38   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 24100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 24200 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 24300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 24400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 24500 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 24600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 24700 ----- Train Accuracy: 0.92   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 24800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 24900 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.34   ----- Test Loss: 0.33   -----•\n",
      "•----- lr 0.001 Iteration 25000 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 25100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 25200 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 25300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 25400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 25500 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.34   ----- Test Loss: 0.33   -----•\n",
      "•----- lr 0.001 Iteration 25600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.35   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 25700 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 25800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 25900 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 26000 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 26100 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 26200 ----- Train Accuracy: 0.92   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 26300 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.37   ----- Test Loss: 0.36   -----•\n",
      "•----- lr 0.001 Iteration 26400 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 26500 ----- Train Accuracy: 0.92   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.34   -----•\n",
      "•----- lr 0.001 Iteration 26600 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 26700 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.92   ----- Train Loss: 0.36   ----- Test Loss: 0.35   -----•\n",
      "•----- lr 0.001 Iteration 26800 ----- Train Accuracy: 0.91   ----- Test Accuracy: 0.91   ----- Train Loss: 0.39   ----- Test Loss: 0.38   -----•\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train at different learning rates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m train_mlp(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_mlp(\u001b[38;5;241m0.1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m, in \u001b[0;36mtrain_mlp\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     train_accuracy, train_loss \u001b[38;5;241m=\u001b[39m mlp_model\u001b[38;5;241m.\u001b[39mevaluate_model(train_list)\n\u001b[0;32m---> 27\u001b[0m     test_accuracy, test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmlp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     train_accuracy_list\u001b[38;5;241m.\u001b[39mappend(train_accuracy)\n\u001b[1;32m     30\u001b[0m     test_accuracy_list\u001b[38;5;241m.\u001b[39mappend(test_accuracy)\n",
      "Cell \u001b[0;32mIn[7], line 76\u001b[0m, in \u001b[0;36mMLP.evaluate_model\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m input_data \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m hidden_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     77\u001b[0m final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwho, hidden_output))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Predict the label\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train at different learning rates\n",
    "train_mlp(0.001)\n",
    "train_mlp(0.01)\n",
    "train_mlp(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
